{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from det2Clo import clo2Detector as c2d\n",
    "from det2Clo import clo2Trainer as c2t\n",
    "from det2Clo import clo2Imagine as c2i\n",
    "\n",
    "from os.path import join\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Define the paths for clothing\n",
    "DATA_PATH = '/home/denny/datasets/deepfashion/'\n",
    "CONF_PATH = join(DATA_PATH, 'conf/train_config.json')\n",
    "YAML_NAME = 'COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml'\n",
    "MODL_PATH = join(DATA_PATH, 'outputs/model_0054999.pth')\n",
    "CATE_PATH = join(DATA_PATH, 'train_descriptions.json')\n",
    "\n",
    "PATH_FOR_CLOTHING = {\n",
    "    'DATA_PATH':str(DATA_PATH), \n",
    "    'CONF_PATH':str(CONF_PATH), \n",
    "    'YAML_NAME':str(YAML_NAME), \n",
    "    'MODL_PATH':str(MODL_PATH), \n",
    "    'CATE_PATH':str(CATE_PATH)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Define the paths for features\n",
    "DATA_PATH = '/home/denny/datasets/iMaterialist/'\n",
    "CONF_PATH = join(DATA_PATH, 'conf/train_config.json')\n",
    "YAML_NAME = 'COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml'\n",
    "MODL_PATH = join(DATA_PATH, 'outputs/model_0034999.pth')\n",
    "CATE_PATH = join(DATA_PATH, 'train_categories.json')\n",
    "\n",
    "PATH_FOR_FEATURES = {\n",
    "    'DATA_PATH':str(DATA_PATH), \n",
    "    'CONF_PATH':str(CONF_PATH), \n",
    "    'YAML_NAME':str(YAML_NAME), \n",
    "    'MODL_PATH':str(MODL_PATH), \n",
    "    'CATE_PATH':str(CATE_PATH)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovelap_hierachy = { v:i for i,v in enumerate([\n",
    "    'shortsleevetop', 'longsleevetop', 'sling', 'vest',\n",
    "    'shortsleeveoutwear', 'longsleeveoutwear', 'shortsleevedress', 'longsleevedress', 'slingdress', 'vestdress',\n",
    "    'trousers', 'shorts', 'skirt',\n",
    "])}\n",
    "PATHS = [PATH_FOR_CLOTHING, PATH_FOR_FEATURES]\n",
    "threshold=[0.3, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers, detectors = list(), list()\n",
    "for i in range(len(PATHS)) : \n",
    "    # ! Make manager for get configuration\n",
    "    managers.append(c2t.Manager(PATHS[i]['DATA_PATH'], PATHS[i]['YAML_NAME'], PATHS[i]['CONF_PATH']))\n",
    "\n",
    "    # ! Make detector for detect clothings\n",
    "    detectors.append(c2d.Detector(managers[i], PATHS[i]['MODL_PATH'], PATHS[i]['CATE_PATH'], threshold=threshold[i], batchsize=512, name=PATHS[i]['DATA_PATH'][-6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we detect the clothing\n",
    "img_path = join(PATHS[0]['DATA_PATH'], 'sample3.jpg')\n",
    "clothing_img, outputs = detectors[0].detect(img_path, resize_width=-1, spec=True)\n",
    "parsed_outputs = detectors[0].parse4specs(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Make stage for show the detected image\n",
    "stage = c2i.Stage()\n",
    "stage.show(clothing_img, tool=\"cv2\", scale=0.8, detects=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we detect the features from masked images\n",
    "masked_imgs = detectors[0].mask2img(clothing_img, parsed_outputs, overlapping=True)\n",
    "feature_img, outputs = detectors[1].detect(masked_imgs[0], resize_width=-1, spec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_img, outputs = detectors[1].detect(masked_imgs[1], resize_width=-1, spec=True)\n",
    "stage.show(feature_img, tool=\"cv2\", scale=0.8, detects=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = c2i.Show(stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2  import cv2\n",
    "from time import sleep\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detected_clothing_to_camera() :\n",
    "    # ! Camera modules\n",
    "    sleep_time_ms = 10\n",
    "\n",
    "    window_main = ['VideoFrame']\n",
    "    window_list = ['Segmentation_Clothing_1', 'Segmentation_Clothing_2', 'Segmentation_Clothing_3']\n",
    "    for wname in (window_main+window_list) : cv2.namedWindow(wname, cv2.WINDOW_NORMAL)\n",
    "    capture = cv2.VideoCapture(1)\n",
    "    capture.set(cv2.CAP_PROP_FRAME_WIDTH,  640)\n",
    "    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    \n",
    "\n",
    "    try :\n",
    "        while True :\n",
    "            ret, frame = capture.read()\n",
    "            if ret : \n",
    "                cv2.imshow(window_main[0], frame)\n",
    "\n",
    "                img, outputs = detectors[0].detect(frame, spec=True)\n",
    "                parsed_outputs = detectors[0].parse4specs(outputs, hierachy=ovelap_hierachy)\n",
    "                masked_imgs = detectors[0].mask2img(img, parsed_outputs, overlapping=True)\n",
    "\n",
    "                for i, mimg in enumerate(masked_imgs[:len(window_list)]) :\n",
    "                    # Put some text to images\n",
    "                    cv2.putText(\n",
    "                        img=mimg, \n",
    "                        text=\"Category name : {}, number : {}\".format(parsed_outputs['labels'][i], parsed_outputs['classes'][i]), \n",
    "                        org=(50, 50),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=0.7,\n",
    "                        color=(0,0,0),\n",
    "                        thickness=2,\n",
    "                        lineType=cv2.LINE_AA,\n",
    "                    )\n",
    "                    \n",
    "                    fimg, outputs = detectors[1].detect(mimg, spec=True)\n",
    "                    \n",
    "                    # Show images\n",
    "                    cv2.imshow(window_list[i], stage.paint(fimg, outputs, scale=1))\n",
    "                    \n",
    "                # default screen\n",
    "                for i in range(0, len(window_list)-len(masked_imgs), 1) :\n",
    "                    cv2.imshow(window_list[len(window_list)-i-1], np.zeros(shape=(100, 100, 3)))\n",
    "\n",
    "            if cv2.waitKey(sleep_time_ms) > 0 :break\n",
    "    except Exception as e :\n",
    "        print(\"ERROR :\", str(e))\n",
    "    finally : \n",
    "        print(\"Done.\")\n",
    "        capture.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "show_detected_clothing_to_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage.draw(stage.paint(img, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
